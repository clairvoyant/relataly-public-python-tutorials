{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #1 Imports and Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tutorial for this file is available at www.relataly.com\n",
    "# Tested with Python 3.9.13, 1.2.0, Pandas 1.3.4, OpenAI 0.27.3, Tweepy 4.13.0, Requests 2.26.0, \n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import openai\n",
    "import tweepy\n",
    "import csv\n",
    "import requests\n",
    "import random\n",
    "\n",
    "# # Set API Keys and Authentification\n",
    "# logging.info('Setting NewsAPI API Key')\n",
    "# NEWSAPI_API_KEY = <your API key> # replace with own API key\n",
    "\n",
    "# logging.info('Setting OpenAI API Key')\n",
    "# openai.api_key = <your API key> # replace with own API key\n",
    "\n",
    "# logging.info('Setting Twitter API Key')\n",
    "# auth=tweepy.OAuthHandler(<your API key>,\n",
    "#                          <your API secret>)\n",
    "# auth.set_access_token(<your access token>,\n",
    "#                       <your access secret>)\n",
    "# twitter_api=tweepy.API(auth)\n",
    "\n",
    "CSV_NEWS_NAME = 'news_log.csv'\n",
    "CSV_FACTS_NAME = 'facts_log.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import AzureCliCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "import tweepy\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import io\n",
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "\n",
    "# Set up the Azure Key Vault client and retrieve the Blob Storage account credentials\n",
    "keyvault_name = 'keyvaultforbot'\n",
    "client = SecretClient(f\"https://{keyvault_name}.vault.azure.net/\", AzureCliCredential())\n",
    "NEWSAPI_API_KEY = client.get_secret('newsapi-api-key').value\n",
    "#### Twitter Auth\n",
    "def twitter_auth():\n",
    "    auth=tweepy.OAuthHandler(client.get_secret('twitter-api-key').value,\n",
    "                            client.get_secret('twitter-api-secret').value)\n",
    "    auth.set_access_token(client.get_secret('twitter-access-token').value,\n",
    "                        client.get_secret('twitter-access-secret').value)\n",
    "    twitter_api=tweepy.API(auth)\n",
    "    logging.info('Twitter API ready')\n",
    "    return twitter_api\n",
    "\n",
    "##### OpenAI API Key\n",
    "openai.api_key = client.get_secret('openai-api-key').value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #2 Function for News API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NewsAPI\n",
    "def fetch_news(number=10):\n",
    "    # Fetch tech news from NewsAPI\n",
    "    url = f\"https://newsapi.org/v2/top-headlines?country=us&category=technology&apiKey={NEWSAPI_API_KEY}\"\n",
    "    response = requests.get(url).json()\n",
    "    news_items = response[\"articles\"]\n",
    "    df = pd.DataFrame(news_items)\n",
    "    df = df[[\"title\", \"description\", \"url\"]].dropna()\n",
    "    return df.head(number)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #3 OpenAI Functions for News Relevance and Tweet Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### OpenAI Engine\n",
    "def openai_request(instructions, task, sample = [], model_engine='gpt-3.5-turbo'):\n",
    "    prompt = [{\"role\": \"system\", \"content\": instructions }, \n",
    "              {\"role\": \"user\", \"content\": task }]\n",
    "    prompt = sample + prompt\n",
    "    completion = openai.ChatCompletion.create(model=model_engine, messages=prompt, temperature=0.2, max_tokens=400)\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "#### Define OpenAI Prompt for news Relevance\n",
    "def select_relevant_news_prompt(news_articles, topics, n):    \n",
    "    instructions = f'Your task is to examine a list of News and return a list of boolean values that indicate which of the News are in scope of a list of topics. \\\n",
    "    Return a list of True or False values that indicate the relevance of the News.'\n",
    "    task =  f\"{news_articles} /n {topics}?\" \n",
    "    sample = [\n",
    "        {\"role\": \"user\", \"content\": f\"[new AI model available from Nvidia, We Exploded the AMD Ryzen 7, Release of b2 Game, XGBoost 3.0 improvices Decision Forest Algorithms, New Zelda Game Now Available, Ukraine Uses a New Weapon] /n {topics}?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"[True, False, False, True, False, False]\"},\n",
    "        {\"role\": \"user\", \"content\": f\"[Giga Giraff found in Sounth Africa, We Exploded the AMD Ryzen 7, Release of b2 Game, Donald Trump to make a come back, New Zelda Game Now Available, Ukraine Uses a New Weapon] /n {topics}?\"}, \n",
    "        {\"role\": \"assistant\", \"content\": \"[False, False, False, False, False, False]\"}]\n",
    "    return instructions, task, sample\n",
    "\n",
    "\n",
    "#### Define OpenAI Prompt for news Relevance\n",
    "def check_previous_posts_prompt(title, old_posts):    \n",
    "    instructions = f'Your objective is to compare a news title with a list of previous news and determine whether it covers a similar topic that was already covered by a previous title. \\\n",
    "        Rate the overlap on a scale between 1 and 10 with 1 beeing a full overlap and 10 representing an unrelated topic. \"'\n",
    "    task =  f\"'{title}.' Previous News: {old_posts}.\"\n",
    "    sample = [\n",
    "        {\"role\": \"user\", \"content\": \"'Nvidia launches new AI model.' Previous News: [new AI model available from Nvidia, We Exploded the AMD Ryzen 7 7800X3D, The Lara Croft Collection For Switch Has Been Rated By The ESRB].\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"1\"},\n",
    "        {\"role\": \"user\", \"content\": \"'Big Explosion of an AMD Ryzen 7.' Previous News: [Improving Mental Wellbeing Through Physical Activity, The Lara Croft Collection For Switch Has Been Rated By The ESRB].\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"10\"},\n",
    "        {\"role\": \"user\", \"content\": \"'new AI model available from Google.' Previous News : [new AI model available from Nvidia, The Lara Croft Collection For Switch Has Been Rated By The ESRB].\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"9\"},\n",
    "        {\"role\": \"user\", \"content\": \"'What Really Made Geoffrey Hinton Into an AI Doomer - WIRED.' Previous News : [Why AI's 'godfather' Geoffrey Hinton quit Google, new AI model available from Nvidia, The Lara Croft Collection For Switch Has Been Rated By The ESRB].\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"4\"}]\n",
    "    return instructions, task, sample\n",
    "\n",
    "\n",
    "#### Define OpenAI Prompt for News Tweet\n",
    "def create_tweet_prompt(title, description, tiny_url):\n",
    "    instructions = f'You are a twitter user that creates tweets with a maximum length of 280 characters.'\n",
    "    task = f\"Create an informative tweet on twitter based on the following news title and description. \\\n",
    "        The tweet must use a maximum of 280 characters. \\\n",
    "        Include the {tiny_url}. But do not include any other urls.\\\n",
    "        Title: {title}. \\\n",
    "        Description: {description}. \\\n",
    "        Use hashtags to reach a wider audience. \\\n",
    "        Do not include any emojis in the tweet\"\n",
    "    return instructions, task\n",
    "\n",
    "\n",
    "#### Define OpenAI Prompt for news Relevance\n",
    "def previous_post_check(title, old_posts):\n",
    "    instructions, task, sample = check_previous_posts_prompt(title, old_posts)\n",
    "    response = openai_request(instructions, task, sample)\n",
    "    return eval(response)\n",
    "\n",
    "\n",
    "#### Define OpenAI Prompt for News Tweet\n",
    "def create_fact_tweet_prompt(old_terms):\n",
    "    instructions = f'You are a twitter user that creates tweets with a length below 280 characters.'\n",
    "    task = f\"Choose a technical term from the field of AI, machine learning or data science. Then create a twitter tweet that describes the term. Just return a python dictionary with the term and the tweet. \"\n",
    "    # if old terms not empty\n",
    "    if old_terms != []:\n",
    "        avoid_terms =f'Avoid the following terms, because you have previously tweetet about them: {old_terms}'\n",
    "        task = task + avoid_terms\n",
    "    sample = [\n",
    "        {\"role\": \"user\", \"content\": f\"Choose a technical term from the field of AI, machine learning or data science. Then create a twitter tweet that describes the term. Just return a python dictionary with the term and the tweet.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"{'GradientDescent': '#GradientDescent is a popular optimization algorithm used to minimize the error of a model by adjusting its parameters. \\\n",
    "         It works by iteratively calculating the gradient of the error with respect to the parameters and updating them accordingly. #ML'}\"}]\n",
    "    return instructions, task, sample\n",
    "\n",
    "# Load previous information from a csv file\n",
    "def get_history_from_csv(csv_name):\n",
    "    try:\n",
    "        # try loading the csv file\n",
    "        df = pd.read_csv(csv_name)\n",
    "    except:\n",
    "        # create the csv file\n",
    "        df = pd.DataFrame(columns=['title'])\n",
    "        df.to_csv(csv_name, index=False)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #4 Functions for Tweeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tweet_length(tweet):\n",
    "    return False if len(tweet) > 280 else True\n",
    "\n",
    "\n",
    "# Create the fact tweet\n",
    "def create_fact_tweet(chance_for_tweet = 0.5):\n",
    "    df_old_facts = get_history_from_csv(CSV_FACTS_NAME)\n",
    "\n",
    "    if random.random() < chance_for_tweet:\n",
    "        # create a fact tweet\n",
    "        instructions, tasks, sample = create_fact_tweet_prompt(list(df_old_facts.tail(10)['title']))\n",
    "        tweet = openai_request(instructions, tasks, sample)\n",
    "        tweet_text = list(eval(tweet).values())[0]\n",
    "\n",
    "        # tweet creation\n",
    "        print(f'Creating fact tweet: {tweet_text}')\n",
    "        \n",
    "        # check tweet length and post tweet\n",
    "        if check_tweet_length(tweet):\n",
    "            twitter_auth().update_status(tweet_text)\n",
    "            term = list(eval(tweet).keys())[0]\n",
    "            # save the fact in the csv file\n",
    "            with open(f'{CSV_FACTS_NAME}', 'a', newline='') as file:\n",
    "                            writer = csv.writer(file)\n",
    "                            writer.writerow([term])\n",
    "        else: \n",
    "            print('error tweet too long')\n",
    "    else:\n",
    "        print('No fact tweet created')\n",
    "    \n",
    "\n",
    "def create_news_tweet(title, description, url):\n",
    "    # create tiny url\n",
    "    tiny_url = create_tiny_url(url)\n",
    "\n",
    "    # define prompt for tweet creation\n",
    "    instructions, task = create_tweet_prompt(title, description, tiny_url)\n",
    "    tweet_text = openai_request(instructions, task)\n",
    "\n",
    "    print(f'Creating new tweet: {tweet_text}')\n",
    "    # check tweet length and post tweet\n",
    "    if check_tweet_length(tweet_text):\n",
    "            status = twitter_auth().update_status(tweet_text)\n",
    "            print(f\"Tweeted: {title}\")\n",
    "            with open(f'{CSV_NEWS_NAME}', 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([title])\n",
    "    else: \n",
    "        status = 'error tweet too long'\n",
    "    return status\n",
    "\n",
    "\n",
    "def create_tiny_url(url):\n",
    "    response = requests.get(f'http://tinyurl.com/api-create.php?url={url}')\n",
    "    return response.text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #5 Bringing it All Together - Running the Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No news articles found\n",
      "No fact tweet created\n",
      "No news articles found\n",
      "Creating fact tweet: Looking for a way to cluster your data? Try #KMeans! It is an unsupervised learning algorithm that groups similar data points together based on their distance to a centroid. #MachineLearning #DataScience\n",
      "Creating tweet: {'KMeans': 'Looking for a way to cluster your data? Try #KMeans! It is an unsupervised learning algorithm that groups similar data points together based on their distance to a centroid. #MachineLearning #DataScience'}\n"
     ]
    }
   ],
   "source": [
    "#### Main Bot\n",
    "def main_bot():\n",
    "    # Read the old CSV data\n",
    "    # try opening the csv file and creeate it if it does not exist\n",
    "    df_old_news = get_history_from_csv(CSV_NEWS_NAME)\n",
    "    df_old_news = df_old_news.tail(16)\n",
    "    # Fetch news data\n",
    "    df = fetch_news(12)\n",
    "    \n",
    "    # Check the Relevance of the News and Filter those not relevant\n",
    "    relevant_topics =\"[AI, Machine Learning, Data Science, OpenAI, Artificial Intelligence, Data Mining, Data Analytics]\"\n",
    "    instructions, task, sample = select_relevant_news_prompt(list(df['title']), relevant_topics, len(list(df['title'])))\n",
    "    relevance = openai_request(instructions, task, sample)\n",
    "    relevance_list = eval(relevance)\n",
    "\n",
    "    s = 0\n",
    "    df = df[relevance_list]\n",
    "    if len(df) > 0:\n",
    "        for index, row in df.iterrows():\n",
    "            if s == 1:\n",
    "                break\n",
    "            logging.info('info:' + row['title'])\n",
    "            title = row['title']\n",
    "            title = title.replace(\"'\", \"\")\n",
    "            description = row['description']\n",
    "            url = row['url']            \n",
    "                                             \n",
    "            if (title not in df_old_news.title.values):\n",
    "                doublicate_check = previous_post_check(title, list(df_old_news.tail(10)['title']))\n",
    "                if doublicate_check > 3:\n",
    "                    # Create a tweet\n",
    "                    response = create_news_tweet(title, description, url)\n",
    "            \n",
    "                else: \n",
    "                    print(f\"Already tweeted: {title}\")\n",
    "            else: \n",
    "                print(\"No news articles found\")\n",
    "                create_fact_tweet(chance_for_tweet=0.5)\n",
    "\n",
    "main_bot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
